La Inteligencia Artificial (IA) ha generado enormes avances en la automatización de procesos y análisis de datos, pero también ha planteado serias preocupaciones éticas. Uno de los principales desafíos es evitar los sesgos en los algoritmos entrenados con datos históricos, los cuales pueden reproducir o incluso amplificar prejuicios sociales existentes. Otro aspecto clave es la privacidad: muchos sistemas de IA requieren grandes volúmenes de información personal para funcionar correctamente, lo que puede comprometer los derechos de los individuos. Organismos internacionales como la UNESCO y la Unión Europea han propuesto marcos normativos para asegurar que el desarrollo de la IA se haga de forma transparente, justa y responsable. En América Latina, aún se está en fases tempranas de regulación, pero países como Brasil, Chile y México han empezado a trabajar en sus propias estrategias nacionales. La pregunta clave que surge es: ¿puede una máquina tomar decisiones que afecten la vida de las personas sin un marco ético sólido?